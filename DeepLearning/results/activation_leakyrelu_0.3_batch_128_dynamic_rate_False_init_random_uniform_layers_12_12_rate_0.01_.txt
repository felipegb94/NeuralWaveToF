Params: {'layers': [12, 12], 'activation': ['leakyrelu', 0.3], 'rate': 0.01, 'batch': 128, 'init': 'random_uniform', 'dynamic_rate': False}
Loss: 1141.72071309

1817.21929961,1248.5148332
1254.13867881,1248.10365879
1253.70643359,1247.67369277
1250.90539473,1241.09373672
1209.88249316,1147.90880117
